import pandas as pd
import time
from tqdm import tqdm
from pathlib import Path

from utils import (
    initialize_ai_model,
    load_data,
    save_data,
    load_checkpoint,
    save_checkpoint,
    process_text_with_ai,
    process_multicolumn_with_ai,
    process_batch_with_ai,
    process_multicolumn_batch_with_ai,
    process_data_parallel,
    process_data_with_async,
    process_data_batch_only,
    generate_output_filename,
    generate_checkpoint_filename,
    clean_text,
    get_processing_stats,
    print_progress_summary,
    logger,
    check_and_retry_failed_rows
)

from config import (
    AI_RESULT_COLUMN,
    CHECKPOINT_INTERVAL,
    PROGRESS_REPORT_INTERVAL,
    ENABLE_BATCH_PROCESSING,
    BATCH_SIZE,
    ENABLE_PARALLEL_PROCESSING,
    ENABLE_ASYNC_PROCESSING,
    MAX_CONCURRENT_THREADS,
    THREAD_BATCH_SIZE,
    MAX_CONCURRENT_REQUESTS,
    ASYNC_RATE_LIMIT_RPM,
    ASYNC_CHUNK_SIZE,
    ENABLE_ERROR_RETRY,
    ERROR_RETRY_MAX_ATTEMPTS
)

class AIDataProcessor:
    """L·ªõp x·ª≠ l√Ω d·ªØ li·ªáu v·ªõi AI"""
    
    def __init__(self, config):
        """Kh·ªüi t·∫°o processor v·ªõi c·∫•u h√¨nh t·ª´ user"""
        self.config = config
        self.model = None
        self.df = None
        self.stats = {
            'processed': 0,
            'errors': 0,
            'start_time': None
        }
        
        # Thi·∫øt l·∫≠p file paths
        self.input_file = config['input_file']
        self.output_file = generate_output_filename(self.input_file)
        self.checkpoint_file = generate_checkpoint_filename(self.input_file) if config['use_checkpoint'] else None
        
    def initialize(self):
        """Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn c·∫ßn thi·∫øt"""
        print("\nüîß KH·ªûI T·∫†O PROCESSOR")
        print("="*50)
        
        # 1. Kh·ªüi t·∫°o AI model
        api_provider_name = "Gemini" if self.config['api_provider'] == 'gemini' else "OpenAI"
        print(f"ü§ñ ƒêang kh·ªüi t·∫°o {api_provider_name} model...")
        fine_tuned_model_info = self.config.get('fine_tuned_model_info')
        self.model = initialize_ai_model(
            self.config['api_provider'],
            self.config['api_key'], 
            self.config['model_name'],
            fine_tuned_model_info
        )
        
        if not self.model:
            print(f"‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o {api_provider_name} model!")
            return False
        
        # 2. Load d·ªØ li·ªáu
        print("üìä ƒêang load d·ªØ li·ªáu...")
        
        # Th·ª≠ load checkpoint tr∆∞·ªõc
        if self.config['use_checkpoint'] and self.checkpoint_file:
            self.df = load_checkpoint(self.checkpoint_file)
            
        # N·∫øu kh√¥ng c√≥ checkpoint, load file g·ªëc
        if self.df is None:
            self.df = load_data(self.input_file)
            
        if self.df is None:
            print("‚ùå Kh√¥ng th·ªÉ load d·ªØ li·ªáu!")
            return False
        
        # 3. Ki·ªÉm tra c·ªôt c·∫ßn x·ª≠ l√Ω
        if self.config.get('multi_column_mode', False):
            # Ki·ªÉm tra t·∫•t c·∫£ c·ªôt ƒë√£ ch·ªçn
            missing_columns = []
            for col in self.config['selected_columns']:
                if col not in self.df.columns:
                    missing_columns.append(col)
            
            if missing_columns:
                print(f"‚ùå Kh√¥ng t√¨m th·∫•y c√°c c·ªôt: {missing_columns}")
                return False
        else:
            # Ki·ªÉm tra c·ªôt ƒë∆°n
            if self.config['message_column'] not in self.df.columns:
                print(f"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt '{self.config['message_column']}' trong file!")
                return False
        
        # 4. Th√™m c·ªôt k·∫øt qu·∫£ n·∫øu ch∆∞a c√≥
        if AI_RESULT_COLUMN not in self.df.columns:
            self.df[AI_RESULT_COLUMN] = ""
        
        # 5. Th·ªëng k√™ d·ªØ li·ªáu
        stats = get_processing_stats(self.df, AI_RESULT_COLUMN)
        
        print(f"‚úÖ Kh·ªüi t·∫°o th√†nh c√¥ng!")
        print(f"üìà T·ªïng s·ªë records: {stats['total']}")
        print(f"‚úÖ ƒê√£ x·ª≠ l√Ω: {stats['processed']}")
        print(f"‚è≥ C√≤n l·∫°i: {stats['remaining']}")
        print(f"‚ùå L·ªói: {stats['errors']}")
        
        if stats['remaining'] == 0:
            print("üéâ T·∫•t c·∫£ d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω!")
            return False
        
        return True
    
    def process_data(self):
        """X·ª≠ l√Ω d·ªØ li·ªáu ch√≠nh v·ªõi Parallel + Batch Processing"""
        print(f"\nüöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù D·ªÆ LI·ªÜU")
        print("="*50)
        
        stats = get_processing_stats(self.df, AI_RESULT_COLUMN)
        self.stats['start_time'] = time.time()
        
        # X√°c ƒë·ªãnh ch·∫ø ƒë·ªô x·ª≠ l√Ω - ∆∞u ti√™n async processing
        is_async_mode = ENABLE_ASYNC_PROCESSING and stats['remaining'] > 10
        is_parallel_mode = ENABLE_PARALLEL_PROCESSING and stats['remaining'] > MAX_CONCURRENT_THREADS and not is_async_mode
        is_batch_mode = ENABLE_BATCH_PROCESSING and stats['remaining'] > 1 and not is_async_mode and not is_parallel_mode
        
        print(f"üéØ S·∫Ω x·ª≠ l√Ω {stats['remaining']} records")
        
        # Hi·ªÉn th·ªã ch·∫ø ƒë·ªô x·ª≠ l√Ω
        if is_async_mode:
            print(f"üöÄ Ch·∫ø ƒë·ªô: Async Processing (SEMAPHORE + RATE LIMITER)")
            print(f"‚ö° Max concurrent: {MAX_CONCURRENT_REQUESTS}")
            print(f"üìä Rate limit: {ASYNC_RATE_LIMIT_RPM} RPM")
            print(f"üì¶ Chunk size: {ASYNC_CHUNK_SIZE}")
            estimated_time_saving = "50-100x faster"
        elif is_parallel_mode:
            print(f"üöÄ Ch·∫ø ƒë·ªô: Parallel + Batch Processing (LEGACY)")
            print(f"üßµ Threads: {MAX_CONCURRENT_THREADS}")
            print(f"üì¶ Thread batch size: {THREAD_BATCH_SIZE}")
            estimated_time_saving = "15-30x faster"
        elif is_batch_mode:
            print(f"üì¶ Ch·∫ø ƒë·ªô: Batch Processing")
            print(f"üì¶ Batch size: {BATCH_SIZE}")
            estimated_time_saving = "5-10x faster"
        else:
            print(f"‚ö° Ch·∫ø ƒë·ªô: Single Processing")
            estimated_time_saving = "baseline"
        
        print(f"‚è±Ô∏è ∆Ø·ªõc t√≠nh c·∫£i thi·ªán t·ªëc ƒë·ªô: {estimated_time_saving}")
        print(f"‚úçÔ∏è Prompt: {self.config['prompt'][:100]}...")
        print("-" * 50)
        
        try:
            if is_async_mode:
                return self._process_with_parallel()  # S·ª≠ d·ª•ng l·∫°i function n√†y nh∆∞ng ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t cho async
            elif is_parallel_mode:
                return self._process_with_parallel()
            elif is_batch_mode:
                return self._process_with_batch()
            else:
                return self._process_without_batch()
                
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è Ng∆∞·ªùi d√πng d·ª´ng ch∆∞∆°ng tr√¨nh...")
            if self.config['use_checkpoint'] and self.checkpoint_file:
                save_checkpoint(self.df, self.checkpoint_file)
                print("üíæ ƒê√£ l∆∞u checkpoint. Ch·∫°y l·∫°i ƒë·ªÉ ti·∫øp t·ª•c.")
            return False
            
        except Exception as e:
            print(f"\nüí• L·ªói kh√¥ng mong mu·ªën: {str(e)}")
            logger.error(f"L·ªói x·ª≠ l√Ω d·ªØ li·ªáu: {str(e)}")
            if self.config['use_checkpoint'] and self.checkpoint_file:
                save_checkpoint(self.df, self.checkpoint_file)
                print("üíæ ƒê√£ l∆∞u checkpoint. Ch·∫°y l·∫°i ƒë·ªÉ ti·∫øp t·ª•c.")
            return False
    
    def _process_with_parallel(self):
        """X·ª≠ l√Ω d·ªØ li·ªáu v·ªõi Async Processing (thay th·∫ø parallel processing)"""
        print("üöÄ Kh·ªüi ƒë·ªông Async Processing...")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu cho async processing
        unprocessed_data = []
        unprocessed_indices = []
        
        for idx in self.df.index:
            if (pd.isna(self.df.at[idx, AI_RESULT_COLUMN]) or 
                self.df.at[idx, AI_RESULT_COLUMN] == ""):
                
                if self.config.get('multi_column_mode', False):
                    # Multi-column mode
                    row_data = {}
                    has_data = False
                    
                    for col in self.config['selected_columns']:
                        value = self.df.at[idx, col]
                        row_data[col] = value
                        if pd.notna(value) and str(value).strip():
                            has_data = True
                    
                    if has_data:
                        unprocessed_data.append(row_data)
                        unprocessed_indices.append(idx)
                    else:
                        self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                else:
                    # Single column mode
                    if pd.notna(self.df.at[idx, self.config['message_column']]):
                        text = clean_text(self.df.at[idx, self.config['message_column']])
                        if text:
                            unprocessed_data.append(text)
                            unprocessed_indices.append(idx)
                        else:
                            self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                    else:
                        self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
        
        if not unprocessed_data:
            print("‚úÖ Kh√¥ng c√≥ d·ªØ li·ªáu c·∫ßn x·ª≠ l√Ω")
            return True
        
        print(f"üìä Chu·∫©n b·ªã x·ª≠ l√Ω {len(unprocessed_data)} items v·ªõi async processing")
        
        # üî• T·∫†O CHECKPOINT CALLBACK FUNCTION
        def async_checkpoint_callback(results_so_far, chunk_completed, total_chunks):
            """Callback ƒë·ªÉ l∆∞u checkpoint trong qu√° tr√¨nh async processing"""
            try:
                # C·∫≠p nh·∫≠t k·∫øt qu·∫£ v√†o DataFrame
                for i, result in enumerate(results_so_far):
                    if i < len(unprocessed_indices):
                        idx = unprocessed_indices[i]
                        self.df.at[idx, AI_RESULT_COLUMN] = result
                        
                # L∆∞u checkpoint
                if self.config['use_checkpoint'] and self.checkpoint_file:
                    save_checkpoint(self.df, self.checkpoint_file)
                    logger.info(f"üíæ Async checkpoint saved: chunk {chunk_completed}/{total_chunks}")
                    
            except Exception as e:
                logger.error(f"‚ùå Error in async checkpoint callback: {e}")
        
        # G·ªçi async processing v·ªõi checkpoint support
        try:
            results = process_data_with_async(
                self.model,
                unprocessed_data,
                self.config.get('selected_columns', []),
                self.config['prompt'],
                self.config.get('multi_column_mode', False),
                checkpoint_callback=async_checkpoint_callback,
                checkpoint_interval=CHECKPOINT_INTERVAL,
                use_json=self.config.get('use_json_output', False)
            )
            
            # L∆∞u k·∫øt qu·∫£ v√†o DataFrame
            for i, result in enumerate(results):
                if i < len(unprocessed_indices):
                    idx = unprocessed_indices[i]
                    self.df.at[idx, AI_RESULT_COLUMN] = result
                    self.stats['processed'] += 1
            
            # L∆∞u checkpoint cu·ªëi c√πng
            if self.config['use_checkpoint'] and self.checkpoint_file:
                save_checkpoint(self.df, self.checkpoint_file)
            
            print(f"‚úÖ Async processing ho√†n th√†nh: {len(results)} k·∫øt qu·∫£")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói async processing: {str(e)}")
            print(f"‚ö†Ô∏è Async processing th·∫•t b·∫°i, fallback v·ªÅ batch processing")
            
            # Fallback v·ªÅ batch processing
            return self._process_with_batch_fallback(unprocessed_data, unprocessed_indices)

    def _process_with_batch_fallback(self, unprocessed_data, unprocessed_indices):
        """Fallback processing khi parallel th·∫•t b·∫°i"""
        try:
            print("üì¶ Chuy·ªÉn sang Batch Processing fallback...")
            
            results = process_data_batch_only(
                self.model,
                unprocessed_data,
                self.config.get('selected_columns', []),
                self.config['prompt'],
                self.config.get('multi_column_mode', False)
            )
            
            # L∆∞u k·∫øt qu·∫£ v√†o DataFrame
            for i, result in enumerate(results):
                if i < len(unprocessed_indices):
                    idx = unprocessed_indices[i]
                    self.df.at[idx, AI_RESULT_COLUMN] = result
                    self.stats['processed'] += 1
            
            # L∆∞u checkpoint
            if self.config['use_checkpoint'] and self.checkpoint_file:
                save_checkpoint(self.df, self.checkpoint_file)
            
            print(f"‚úÖ Batch processing fallback ho√†n th√†nh: {len(results)} k·∫øt qu·∫£")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Batch processing fallback c≈©ng th·∫•t b·∫°i: {str(e)}")
            print("‚ö†Ô∏è Fallback v·ªÅ single processing...")
            
            # Final fallback v·ªÅ single processing
            return self._process_single_fallback(unprocessed_data, unprocessed_indices)
    
    def _process_single_fallback(self, unprocessed_data, unprocessed_indices):
        """Final fallback v·ªÅ single processing"""
        try:
            print("‚ö° Single processing fallback...")
            
            for i, data in enumerate(unprocessed_data):
                if i >= len(unprocessed_indices):
                    break
                    
                idx = unprocessed_indices[i]
                
                try:
                    if self.config.get('multi_column_mode', False):
                        result = process_multicolumn_with_ai(
                            self.model,
                            data,
                            self.config['selected_columns'],
                            self.config['prompt']
                        )
                    else:
                        result = process_text_with_ai(
                            self.model,
                            str(data),
                            self.config['prompt']
                        )
                    
                    self.df.at[idx, AI_RESULT_COLUMN] = result
                    self.stats['processed'] += 1
                    
                except Exception as single_error:
                    self.stats['errors'] += 1
                    self.df.at[idx, AI_RESULT_COLUMN] = f"L·ªói x·ª≠ l√Ω: {str(single_error)}"
                    logger.error(f"L·ªói single processing t·∫°i {idx}: {str(single_error)}")
            
            # L∆∞u checkpoint
            if self.config['use_checkpoint'] and self.checkpoint_file:
                save_checkpoint(self.df, self.checkpoint_file)
            
            print(f"‚úÖ Single processing fallback ho√†n th√†nh: {self.stats['processed']} records")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Single processing fallback th·∫•t b·∫°i: {str(e)}")
            return False

    def _process_with_batch(self):
        """X·ª≠ l√Ω d·ªØ li·ªáu v·ªõi batch processing"""
        # L·∫•y danh s√°ch c√°c record c·∫ßn x·ª≠ l√Ω
        unprocessed_indices = []
        for idx in self.df.index:
            if (pd.isna(self.df.at[idx, AI_RESULT_COLUMN]) or 
                self.df.at[idx, AI_RESULT_COLUMN] == ""):
                unprocessed_indices.append(idx)
        
        total_batches = (len(unprocessed_indices) + BATCH_SIZE - 1) // BATCH_SIZE
        
        # T·∫°o progress bar cho batches
        progress_bar = tqdm(
            range(total_batches),
            desc="X·ª≠ l√Ω batches",
            ncols=100
        )
        
        for batch_idx in progress_bar:
            start_idx = batch_idx * BATCH_SIZE
            end_idx = min(start_idx + BATCH_SIZE, len(unprocessed_indices))
            batch_indices = unprocessed_indices[start_idx:end_idx]
            
            try:
                if self.config.get('multi_column_mode', False):
                    # Batch processing cho multi-column
                    batch_rows = []
                    valid_indices = []
                    
                    for idx in batch_indices:
                        row_data = {}
                        has_data = False
                        
                        for col in self.config['selected_columns']:
                            value = self.df.at[idx, col]
                            row_data[col] = value
                            if pd.notna(value) and str(value).strip():
                                has_data = True
                        
                        if has_data:
                            batch_rows.append(row_data)
                            valid_indices.append(idx)
                        else:
                            self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                    
                    if batch_rows:
                        # X·ª≠ l√Ω batch multi-column
                        results = process_multicolumn_batch_with_ai(
                            self.model,
                            batch_rows,
                            self.config['selected_columns'],
                            self.config['prompt']
                        )
                        
                        # L∆∞u k·∫øt qu·∫£
                        for i, result in enumerate(results):
                            if i < len(valid_indices):
                                self.df.at[valid_indices[i], AI_RESULT_COLUMN] = result
                                self.stats['processed'] += 1
                
                else:
                    # Batch processing cho single column
                    batch_data = []
                    valid_indices = []
                    
                    for idx in batch_indices:
                        if pd.notna(self.df.at[idx, self.config['message_column']]):
                            text = clean_text(self.df.at[idx, self.config['message_column']])
                            if text:
                                batch_data.append(text)
                                valid_indices.append(idx)
                            else:
                                self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                        else:
                            self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                    
                    if batch_data:
                        # X·ª≠ l√Ω batch single column
                        results = process_batch_with_ai(
                            self.model,
                            batch_data,
                            self.config['prompt']
                        )
                        
                        # L∆∞u k·∫øt qu·∫£
                        for i, result in enumerate(results):
                            if i < len(valid_indices):
                                self.df.at[valid_indices[i], AI_RESULT_COLUMN] = result
                                self.stats['processed'] += 1
                
                # C·∫≠p nh·∫≠t progress bar
                progress_bar.set_description(f"ƒê√£ x·ª≠ l√Ω: {self.stats['processed']} records")
                
                # L∆∞u checkpoint ƒë·ªãnh k·ª≥
                if (self.config['use_checkpoint'] and 
                    self.checkpoint_file and
                    (batch_idx + 1) % (CHECKPOINT_INTERVAL // BATCH_SIZE) == 0):
                    
                    save_checkpoint(self.df, self.checkpoint_file)
                
                # B√°o c√°o ti·∫øn tr√¨nh ƒë·ªãnh k·ª≥
                if (batch_idx + 1) % (PROGRESS_REPORT_INTERVAL // BATCH_SIZE) == 0:
                    print_progress_summary(
                        self.stats['processed'], 
                        len(self.df), 
                        self.stats['start_time'], 
                        self.stats['errors']
                    )
                
            except Exception as e:
                logger.error(f"‚ùå L·ªói x·ª≠ l√Ω batch {batch_idx + 1}: {str(e)}")
                # Fallback: x·ª≠ l√Ω t·ª´ng record trong batch n√†y
                for idx in batch_indices:
                    try:
                        if self.config.get('multi_column_mode', False):
                            row_data = {}
                            has_data = False
                            for col in self.config['selected_columns']:
                                value = self.df.at[idx, col]
                                row_data[col] = value
                                if pd.notna(value) and str(value).strip():
                                    has_data = True
                            
                            if has_data:
                                result = process_multicolumn_with_ai(
                                    self.model,
                                    row_data,
                                    self.config['selected_columns'],
                                    self.config['prompt']
                                )
                                self.df.at[idx, AI_RESULT_COLUMN] = result
                                self.stats['processed'] += 1
                            else:
                                self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                        else:
                            if pd.notna(self.df.at[idx, self.config['message_column']]):
                                text = clean_text(self.df.at[idx, self.config['message_column']])
                                if text:
                                    result = process_text_with_ai(
                                        self.model, 
                                        text, 
                                        self.config['prompt']
                                    )
                                    self.df.at[idx, AI_RESULT_COLUMN] = result
                                    self.stats['processed'] += 1
                                else:
                                    self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                            else:
                                self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                    except Exception as single_error:
                        self.stats['errors'] += 1
                        self.df.at[idx, AI_RESULT_COLUMN] = f"L·ªói x·ª≠ l√Ω: {str(single_error)}"
                        logger.error(f"L·ªói t·∫°i row {idx}: {str(single_error)}")
        
        progress_bar.close()
        
        # B√°o c√°o cu·ªëi c√πng
        print_progress_summary(
            self.stats['processed'], 
            len(self.df), 
            self.stats['start_time'], 
            self.stats['errors']
        )
        
        return True

    def _process_without_batch(self):
        """X·ª≠ l√Ω d·ªØ li·ªáu kh√¥ng d√πng batch processing (legacy mode)"""
        stats = get_processing_stats(self.df, AI_RESULT_COLUMN)
        
        # T·∫°o progress bar
        progress_bar = tqdm(
            self.df.index, 
            desc="X·ª≠ l√Ω d·ªØ li·ªáu", 
            ncols=100,
            initial=stats['processed']
        )
        
        for idx in progress_bar:
            # B·ªè qua n·∫øu ƒë√£ x·ª≠ l√Ω
            if (pd.notna(self.df.at[idx, AI_RESULT_COLUMN]) and 
                self.df.at[idx, AI_RESULT_COLUMN] != ""):
                continue
            
            try:
                # X·ª≠ l√Ω theo ch·∫ø ƒë·ªô
                if self.config.get('multi_column_mode', False):
                    # Ch·∫ø ƒë·ªô nhi·ªÅu c·ªôt
                    row_data = {}
                    has_data = False
                    
                    for col in self.config['selected_columns']:
                        value = self.df.at[idx, col]
                        row_data[col] = value
                        if pd.notna(value) and str(value).strip():
                            has_data = True
                    
                    if not has_data:
                        self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                        continue
                    
                    # X·ª≠ l√Ω v·ªõi AI multi-column
                    result = process_multicolumn_with_ai(
                        self.model,
                        row_data,
                        self.config['selected_columns'],
                        self.config['prompt']
                    )
                else:
                    # Ch·∫ø ƒë·ªô c·ªôt ƒë∆°n
                    if pd.isna(self.df.at[idx, self.config['message_column']]):
                        continue
                    
                    # L·∫•y v√† l√†m s·∫°ch text
                    text = clean_text(self.df.at[idx, self.config['message_column']])
                    
                    if not text:
                        self.df.at[idx, AI_RESULT_COLUMN] = "Kh√¥ng c√≥ d·ªØ li·ªáu"
                        continue
                    
                    # X·ª≠ l√Ω v·ªõi AI
                    result = process_text_with_ai(
                        self.model, 
                        text, 
                        self.config['prompt']
                    )
                
                # L∆∞u k·∫øt qu·∫£
                self.df.at[idx, AI_RESULT_COLUMN] = result
                self.stats['processed'] += 1
                
                # C·∫≠p nh·∫≠t progress bar
                progress_bar.set_description(f"ƒê√£ x·ª≠ l√Ω: {self.stats['processed']}")
                
            except Exception as e:
                self.stats['errors'] += 1
                self.df.at[idx, AI_RESULT_COLUMN] = f"L·ªói x·ª≠ l√Ω: {str(e)}"
                logger.error(f"L·ªói t·∫°i row {idx}: {str(e)}")
            
            # L∆∞u checkpoint ƒë·ªãnh k·ª≥
            if (self.config['use_checkpoint'] and 
                self.checkpoint_file and
                self.stats['processed'] % CHECKPOINT_INTERVAL == 0 and 
                self.stats['processed'] > 0):
                
                save_checkpoint(self.df, self.checkpoint_file)
            
            # B√°o c√°o ti·∫øn tr√¨nh ƒë·ªãnh k·ª≥
            if (self.stats['processed'] % PROGRESS_REPORT_INTERVAL == 0 and 
                self.stats['processed'] > 0):
                
                print_progress_summary(
                    self.stats['processed'], 
                    stats['total'], 
                    self.stats['start_time'], 
                    self.stats['errors']
                )
        
        progress_bar.close()
        
        # B√°o c√°o cu·ªëi c√πng
        print_progress_summary(
            self.stats['processed'], 
            stats['total'], 
            self.stats['start_time'], 
            self.stats['errors']
        )
        
        return True
    
    def save_results(self):
        """L∆∞u k·∫øt qu·∫£ cu·ªëi c√πng"""
        print(f"\nüíæ L∆ØU K·∫æT QU·∫¢")
        print("="*50)
        
        # B∆Ø·ªöC M·ªöI: Ki·ªÉm tra v√† retry c√°c row b·ªã l·ªói tr∆∞·ªõc khi l∆∞u
        if ENABLE_ERROR_RETRY:
            print("\nüîç KI·ªÇM TRA V√Ä X·ª¨ L√ù L·∫†I C√ÅC ROW B·ªä L·ªñI...")
            print("-"*50)
            
            try:
                # X√°c ƒë·ªãnh th√¥ng s·ªë cho retry
                if self.config.get('multi_column_mode', False):
                    column_names = self.config['selected_columns']
                    is_multicolumn = True
                else:
                    column_names = self.config['message_column']
                    is_multicolumn = False
                
                # Ch·∫°y retry failed rows v·ªõi config
                retry_stats = check_and_retry_failed_rows(
                    df=self.df,
                    result_column=AI_RESULT_COLUMN,
                    model=self.model,
                    column_names=column_names,
                    prompt=self.config['prompt'],
                    is_multicolumn=is_multicolumn,
                    max_retry_attempts=ERROR_RETRY_MAX_ATTEMPTS
                )
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ retry
                if retry_stats['total_errors'] > 0:
                    print(f"\nüìä K·∫æT QU·∫¢ RETRY:")
                    print(f"   üî• T·ªïng l·ªói t√¨m th·∫•y: {retry_stats['total_errors']}")
                    print(f"   üîÑ ƒê√£ th·ª≠ retry: {retry_stats['retry_attempted']}")
                    print(f"   ‚úÖ Retry th√†nh c√¥ng: {retry_stats['retry_success']}")
                    print(f"   ‚ùå Retry th·∫•t b·∫°i: {retry_stats['retry_failed']}")
                    
                    if retry_stats['retry_success'] > 0:
                        success_rate = (retry_stats['retry_success'] / retry_stats['retry_attempted']) * 100
                        print(f"   üìà T·ª∑ l·ªá retry th√†nh c√¥ng: {success_rate:.1f}%")
                        
                        # C·∫≠p nh·∫≠t stats t·ªïng
                        self.stats['processed'] += retry_stats['retry_success']
                        if retry_stats['retry_failed'] > retry_stats['retry_success']:
                            self.stats['errors'] += (retry_stats['retry_failed'] - retry_stats['retry_success'])
                        else:
                            self.stats['errors'] = max(0, self.stats['errors'] - retry_stats['retry_success'])
                else:
                    print("‚úÖ Kh√¥ng c√≥ row n√†o b·ªã l·ªói c·∫ßn retry!")
                    
            except Exception as retry_error:
                print(f"‚ö†Ô∏è L·ªói trong qu√° tr√¨nh retry: {str(retry_error)}")
                print("Ti·∫øp t·ª•c l∆∞u file v·ªõi d·ªØ li·ªáu hi·ªán t·∫°i...")
        
        print("\nüíæ L∆∞u file k·∫øt qu·∫£...")
        success = save_data(self.df, self.output_file)
        
        if success:
            print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£: {Path(self.output_file).name}")
            
            # Th·ªëng k√™ cu·ªëi c√πng (sau retry)
            final_stats = get_processing_stats(self.df, AI_RESULT_COLUMN)
            print(f"\nüìä TH·ªêNG K√ä CU·ªêI C√ôNG:")
            print(f"   - T·ªïng records: {final_stats['total']}")
            print(f"   - ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng: {final_stats['processed']}")
            print(f"   - C√≤n l·ªói: {final_stats['errors']}")
            print(f"   - Ch∆∞a x·ª≠ l√Ω: {final_stats['remaining']}")
            
            # T√≠nh t·ª∑ l·ªá th√†nh c√¥ng th·ª±c t·∫ø
            actual_success = final_stats['processed']
            total_records = final_stats['total']
            success_rate = (actual_success / total_records * 100) if total_records > 0 else 0
            print(f"   - T·ª∑ l·ªá th√†nh c√¥ng: {success_rate:.1f}%")
            
            # X√≥a checkpoint n·∫øu ho√†n th√†nh t·ªët
            remaining_errors = final_stats['errors'] + final_stats['remaining']
            if (self.config['use_checkpoint'] and 
                self.checkpoint_file and 
                remaining_errors == 0):  # Kh√¥ng c√≤n l·ªói v√† ch∆∞a x·ª≠ l√Ω
                try:
                    Path(self.checkpoint_file).unlink(missing_ok=True)
                    print("üóëÔ∏è ƒê√£ x√≥a checkpoint file (ho√†n th√†nh 100%)")
                except:
                    pass
            elif remaining_errors > 0:
                print(f"üíæ Gi·ªØ checkpoint file (c√≤n {remaining_errors} records ch∆∞a ho√†n th√†nh)")
            
            return True
        else:
            print("‚ùå L·ªói l∆∞u file k·∫øt qu·∫£!")
            return False
    
    def run(self):
        """Ch·∫°y to√†n b·ªô qu√° tr√¨nh x·ª≠ l√Ω"""
        print("\nüéØ B·∫ÆT ƒê·∫¶U QU√Å TR√åNH X·ª¨ L√ù AI ETL DATA")
        print("="*60)
        
        # 1. Kh·ªüi t·∫°o
        if not self.initialize():
            return False
        
        # 2. X·ª≠ l√Ω d·ªØ li·ªáu
        if not self.process_data():
            return False
        
        # 3. L∆∞u k·∫øt qu·∫£
        if not self.save_results():
            return False
        
        # 4. T·ªïng k·∫øt
        elapsed_hours = (time.time() - self.stats['start_time']) / 3600
        print(f"\nüéâ HO√ÄN TH√ÄNH!")
        print("="*60)
        print(f"‚è±Ô∏è T·ªïng th·ªùi gian: {elapsed_hours:.2f} gi·ªù")
        print(f"‚ö° T·ªëc ƒë·ªô trung b√¨nh: {self.stats['processed']/elapsed_hours:.0f} records/gi·ªù")
        print(f"üìÅ File k·∫øt qu·∫£: {Path(self.output_file).name}")
        print(f"üìç V·ªã tr√≠: {Path(self.output_file).parent}")
        
        return True

def run_processor(config):
    """H√†m ti·ªán √≠ch ƒë·ªÉ ch·∫°y processor"""
    processor = AIDataProcessor(config)
    return processor.run() 