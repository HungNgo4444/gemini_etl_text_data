#!/usr/bin/env python3
"""
Speed test Ä‘Æ¡n giáº£n cho async vs batch processing
"""

import time
import asyncio
from utils import process_data_with_async, process_data_batch_only, initialize_ai_model
from config import *

def create_test_data(size=20):
    """Táº¡o test data"""
    data = []
    for i in range(size):
        data.append({
            'MESSAGE': f'Test message {i+1}: ÄÃ¢y lÃ  ná»™i dung test Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tá»‘c Ä‘á»™ xá»­ lÃ½.',
            'ID': i+1
        })
    return data

async def test_async_processing():
    """Test async processing"""
    print("ğŸ”§ ASYNC PROCESSING TEST")
    print("=" * 40)
    
    # Setup
    api_provider = "openai"  # Thay Ä‘á»•i theo nhu cáº§u
    api_key = "your-api-key"  # Thay Ä‘á»•i
    model_name = "gpt-4o-mini"
    test_size = 10
    
    prompt = "PhÃ¢n tÃ­ch cáº£m xÃºc: TÃCH Cá»°C, TIÃŠU Cá»°C hoáº·c TRUNG TÃNH"
    
    # Táº¡o data vÃ  model
    test_data = create_test_data(test_size)
    model_obj = initialize_ai_model(api_provider, api_key, model_name)
    
    print(f"ğŸ“Š Test size: {test_size} items")
    print(f"ğŸ“Š ASYNC_BATCH_SIZE: {ASYNC_BATCH_SIZE}")
    print(f"ğŸ“Š MAX_CONCURRENT_REQUESTS: {MAX_CONCURRENT_REQUESTS}")
    
    # Test async
    print(f"\nğŸš€ Testing ASYNC processing...")
    start_time = time.time()
    
    try:
        async_results = await process_data_with_async(
            model=model_obj,
            data=test_data,
            column_names=['MESSAGE'],
            prompt=prompt,
            is_multicolumn=False
        )
        
        async_time = time.time() - start_time
        async_throughput = test_size / async_time
        
        print(f"âœ… ASYNC: {async_time:.2f}s ({async_throughput:.2f} items/s)")
        
    except Exception as e:
        print(f"âŒ ASYNC FAILED: {str(e)}")
        async_time = None
        async_results = None
    
    # Delay
    print(f"\nâ³ Waiting 5s...")
    await asyncio.sleep(5)
    
    # Test batch
    print(f"\nğŸ“¦ Testing BATCH processing...")
    start_time = time.time()
    
    try:
        batch_results = process_data_batch_only(
            model=model_obj,
            data=test_data,
            column_names=['MESSAGE'],
            prompt=prompt,
            is_multicolumn=False
        )
        
        batch_time = time.time() - start_time
        batch_throughput = test_size / batch_time
        
        print(f"âœ… BATCH: {batch_time:.2f}s ({batch_throughput:.2f} items/s)")
        
    except Exception as e:
        print(f"âŒ BATCH FAILED: {str(e)}")
        batch_time = None
        batch_results = None
    
    # Comparison
    print(f"\nğŸ† COMPARISON")
    print("=" * 40)
    
    if async_time and batch_time:
        if async_time < batch_time:
            improvement = batch_time / async_time
            print(f"ğŸš€ ASYNC is {improvement:.2f}x FASTER!")
        else:
            improvement = async_time / batch_time
            print(f"ğŸ“¦ BATCH is {improvement:.2f}x FASTER!")
        
        print(f"âš¡ Async:  {async_time:.2f}s")
        print(f"ğŸ“¦ Batch:  {batch_time:.2f}s")
    else:
        print("âŒ Could not compare due to errors")

if __name__ == "__main__":
    print("ğŸ¯ SIMPLE SPEED TEST")
    print("=" * 50)
    print("âš ï¸  Please edit the script to add your API key!")
    print()
    
    # Uncomment Ä‘á»ƒ cháº¡y test:
    # asyncio.run(test_async_processing())
    
    print("âœ… Script loaded successfully. Edit API key and uncomment the last line to run.") 