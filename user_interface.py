import os
import sys
from pathlib import Path
from config import AVAILABLE_GEMINI_MODELS, AVAILABLE_OPENAI_MODELS, DEFAULT_PROMPT_TEMPLATES
from utils import validate_file_path, validate_prompt, detect_message_column, load_data, load_fine_tuned_models

# Ki·ªÉm tra OpenAI availability
def check_openai_available():
    """Ki·ªÉm tra OpenAI availability ƒë·ªông"""
    try:
        from utils import check_openai_availability
        available, _ = check_openai_availability()
        return available
    except ImportError:
        return False

OPENAI_AVAILABLE = check_openai_available()

def load_prompt_from_file():
    """Load prompt t·ª´ file text"""
    while True:
        file_path = input("\nNh·∫≠p ƒë∆∞·ªùng d·∫´n file prompt (.txt): ").strip()
        
        # Lo·∫°i b·ªè d·∫•u ngo·∫∑c k√©p n·∫øu c√≥
        file_path = file_path.strip('"').strip("'")
        
        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not os.path.exists(file_path):
            print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {file_path}")
            retry = input("Th·ª≠ l·∫°i? (y/n): ").strip().lower()
            if retry not in ['y', 'yes', 'c√≥']:
                return None
            continue
        
        # Ki·ªÉm tra ph·∫ßn m·ªü r·ªông
        if not file_path.lower().endswith('.txt'):
            print(f"‚ùå Ch·ªâ h·ªó tr·ª£ file .txt")
            retry = input("Th·ª≠ l·∫°i? (y/n): ").strip().lower()
            if retry not in ['y', 'yes', 'c√≥']:
                return None
            continue
        
        try:
            # Th·ª≠ ƒë·ªçc file v·ªõi c√°c encoding kh√°c nhau
            encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252']
            content = None
            
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read().strip()
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file v·ªõi c√°c encoding th√¥ng d·ª•ng")
                retry = input("Th·ª≠ l·∫°i? (y/n): ").strip().lower()
                if retry not in ['y', 'yes', 'c√≥']:
                    return None
                continue
            
            if not content:
                print(f"‚ùå File r·ªóng ho·∫∑c kh√¥ng c√≥ n·ªôi dung")
                retry = input("Th·ª≠ l·∫°i? (y/n): ").strip().lower()
                if retry not in ['y', 'yes', 'c√≥']:
                    return None
                continue
            
            # Validate prompt
            is_valid, message = validate_prompt(content)
            if not is_valid:
                print(f"‚ùå {message}")
                retry = input("Th·ª≠ l·∫°i? (y/n): ").strip().lower()
                if retry not in ['y', 'yes', 'c√≥']:
                    return None
                continue
            
            print(f"‚úÖ ƒê√£ ƒë·ªçc th√†nh c√¥ng file: {Path(file_path).name}")
            print(f"üìù ƒê·ªô d√†i prompt: {len(content)} k√Ω t·ª±")
            
            return content
            
        except Exception as e:
            print(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")
            retry = input("Th·ª≠ l·∫°i? (y/n): ").strip().lower()
            if retry not in ['y', 'yes', 'c√≥']:
                return None

def get_user_input():
    """Thu th·∫≠p th√¥ng tin t·ª´ ng∆∞·ªùi d√πng"""
    print("üöÄ AI ETL DATA - X·ª≠ l√Ω d·ªØ li·ªáu text v·ªõi AI")
    print("="*60)
    
    user_config = {}
    
    # 1. Ch·ªçn API Provider
    print("\nüîß B∆Ø·ªöC 1: Ch·ªçn API Provider")
    print("-" * 40)
    print("1. Gemini AI (Google)")
    
    # Ki·ªÉm tra l·∫°i ƒë·ªông
    openai_available = check_openai_available()
    available_options = ["1"]
    if openai_available:
        print("2. OpenAI (ChatGPT)")
        available_options.append("2")
    else:
        print("2. OpenAI (ChatGPT) - ‚ùå Kh√¥ng c√≥ s·∫µn (c·∫ßn c√†i ƒë·∫∑t: pip install openai>=1.0.0)")
    
    max_option = len(available_options)
    prompt_text = f"\nCh·ªçn API provider ({'/'.join(available_options)}): " if max_option > 1 else "\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c v·ªõi Gemini AI: "
    
    while True:
        if max_option == 1:
            input(prompt_text)
            user_config['api_provider'] = 'gemini'
            print("‚úÖ ƒê√£ ch·ªçn Gemini AI")
            break
        else:
            provider_choice = input(prompt_text).strip()
            if provider_choice == "1":
                user_config['api_provider'] = 'gemini'
                print("‚úÖ ƒê√£ ch·ªçn Gemini AI")
                break
            elif provider_choice == "2" and openai_available:
                user_config['api_provider'] = 'openai'
                print("‚úÖ ƒê√£ ch·ªçn OpenAI")
                break
            else:
                if not openai_available and provider_choice == "2":
                    print("‚ùå OpenAI kh√¥ng c√≥ s·∫µn. Vui l√≤ng c√†i ƒë·∫∑t: pip install openai>=1.0.0")
                else:
                    print(f"‚ùå Vui l√≤ng ch·ªçn {' ho·∫∑c '.join(available_options)}")
    
    # 2. Nh·∫≠p API Key
    api_provider_name = "Gemini" if user_config['api_provider'] == 'gemini' else "OpenAI"
    print(f"\nüì° B∆Ø·ªöC 2: C·∫•u h√¨nh API {api_provider_name}")
    print("-" * 40)
    
    while True:
        api_key = input(f"Nh·∫≠p {api_provider_name} API Key: ").strip()
        if api_key:
            user_config['api_key'] = api_key
            print("‚úÖ API Key ƒë√£ ƒë∆∞·ª£c nh·∫≠p")
            break
        print("‚ùå API Key kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!")
    
    # 3. Ch·ªçn model
    print(f"\nü§ñ B∆Ø·ªöC 3: Ch·ªçn model AI")
    print("-" * 40)
    
    # Ch·ªçn models d·ª±a tr√™n provider
    if user_config['api_provider'] == 'gemini':
        # Load fine-tuned models cho Gemini
        fine_tuned_models = load_fine_tuned_models()
        all_models = []
        model_info = {}
        
        # Th√™m standard Gemini models
        print("üìã GEMINI STANDARD MODELS:")
        for i, model in enumerate(AVAILABLE_GEMINI_MODELS, 1):
            print(f"  {i}. {model}")
            all_models.append(model)
            model_info[model] = None  # Standard model
        
        # Th√™m fine-tuned models n·∫øu c√≥
        if fine_tuned_models:
            print("\nüéØ GEMINI FINE-TUNED MODELS:")
            for name, info in fine_tuned_models.items():
                index = len(all_models) + 1
                display_name = info.get('display_name', name)
                training_date = info.get('training_date', 'N/A')[:10]  # Only date part
                print(f"  {index}. {display_name} (Fine-tuned: {training_date})")
                all_models.append(name)
                model_info[name] = info
    else:
        # OpenAI models
        all_models = AVAILABLE_OPENAI_MODELS.copy()
        model_info = {model: None for model in all_models}
        fine_tuned_models = None
        
        print("üìã OPENAI MODELS:")
        for i, model in enumerate(AVAILABLE_OPENAI_MODELS, 1):
            print(f"  {i}. {model}")
    
    while True:
        try:
            choice = input(f"\nCh·ªçn model (1-{len(all_models)}) ho·∫∑c nh·∫≠p t√™n model kh√°c: ").strip()
            
            # Ki·ªÉm tra n·∫øu l√† s·ªë
            if choice.isdigit():
                model_index = int(choice) - 1
                if 0 <= model_index < len(all_models):
                    selected_model = all_models[model_index]
                    user_config['model_name'] = selected_model
                    user_config['fine_tuned_model_info'] = model_info[selected_model]
                    
                    # Hi·ªÉn th·ªã info cho fine-tuned model
                    if user_config['api_provider'] == 'gemini' and model_info[selected_model]:
                        print(f"‚úÖ ƒê√£ ch·ªçn fine-tuned Gemini model: {selected_model}")
                        print(f"üìÖ Training date: {model_info[selected_model].get('training_date', 'N/A')[:19]}")
                        if model_info[selected_model].get('requires_context'):
                            print(f"üéØ Model n√†y s·ª≠ d·ª•ng prompt context t·ª´ fine-tuning")
                    else:
                        api_name = "Gemini" if user_config['api_provider'] == 'gemini' else "OpenAI"
                        print(f"‚úÖ ƒê√£ ch·ªçn {api_name} model: {selected_model}")
                    break
                else:
                    print(f"‚ùå Vui l√≤ng ch·ªçn t·ª´ 1 ƒë·∫øn {len(all_models)}")
            else:
                # Ng∆∞·ªùi d√πng nh·∫≠p t√™n model kh√°c
                if choice:
                    user_config['model_name'] = choice
                    user_config['fine_tuned_model_info'] = None
                    api_name = "Gemini" if user_config['api_provider'] == 'gemini' else "OpenAI"
                    print(f"‚úÖ ƒê√£ ch·ªçn custom {api_name} model: {choice}")
                    break
                print("‚ùå T√™n model kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!")
        except ValueError:
            print("‚ùå Vui l√≤ng nh·∫≠p s·ªë h·ª£p l·ªá!")
    
    # 4. Nh·∫≠p ƒë∆∞·ªùng d·∫´n file input
    print("\nüìÅ B∆Ø·ªöC 4: Ch·ªçn file d·ªØ li·ªáu")
    print("-" * 40)
    
    while True:
        file_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n file c·∫ßn x·ª≠ l√Ω (.xlsx, .csv): ").strip()
        
        # Lo·∫°i b·ªè d·∫•u ngo·∫∑c k√©p n·∫øu c√≥
        file_path = file_path.strip('"').strip("'")
        
        is_valid, message = validate_file_path(file_path)
        if is_valid:
            user_config['input_file'] = file_path
            print(f"‚úÖ {message}")
            break
        else:
            print(f"‚ùå {message}")
    
    # 5. Ch·ªçn c·ªôt c·∫ßn x·ª≠ l√Ω
    print("\nüìä B∆Ø·ªöC 5: Ch·ªçn c·ªôt d·ªØ li·ªáu")
    print("-" * 40)
    
    # Load file ƒë·ªÉ hi·ªÉn th·ªã c√°c c·ªôt
    print("üîç ƒêang ph√¢n t√≠ch file...")
    df = load_data(user_config['input_file'])
    
    if df is not None:
        print(f"üìà File c√≥ {len(df)} d√≤ng d·ªØ li·ªáu")
        print("C√°c c·ªôt c√≥ s·∫µn:")
        for i, col in enumerate(df.columns, 1):
            # Hi·ªÉn th·ªã preview d·ªØ li·ªáu
            sample_data = df[col].dropna().iloc[0] if len(df[col].dropna()) > 0 else "N/A"
            if len(str(sample_data)) > 50:
                sample_data = str(sample_data)[:50] + "..."
            print(f"  {i}. {col} (VD: {sample_data})")
        
        # T·ª± ƒë·ªông detect c·ªôt message
        detected_col = detect_message_column(df)
        if detected_col:
            print(f"\nüí° T·ª± ƒë·ªông ph√°t hi·ªán c·ªôt text: '{detected_col}'")
        
        print("\nüéØ T√πy ch·ªçn l·ª±a ch·ªçn c·ªôt:")
        print("  1Ô∏è‚É£  Ch·ªçn 1 c·ªôt duy nh·∫•t")
        print("  2Ô∏è‚É£  Ch·ªçn nhi·ªÅu c·ªôt ƒë·ªÉ gh√©p l·∫°i")
        
        while True:
            mode_choice = input("\nCh·ªçn ch·∫ø ƒë·ªô (1 ho·∫∑c 2): ").strip()
            
            if mode_choice == "1":
                # Ch·∫ø ƒë·ªô ch·ªçn 1 c·ªôt duy nh·∫•t
                while True:
                    choice = input(f"\nCh·ªçn c·ªôt c·∫ßn x·ª≠ l√Ω (1-{len(df.columns)}) ho·∫∑c nh·∫≠p t√™n c·ªôt: ").strip()
                    
                    if choice.isdigit():
                        col_index = int(choice) - 1
                        if 0 <= col_index < len(df.columns):
                            user_config['message_column'] = df.columns[col_index]
                            user_config['selected_columns'] = [df.columns[col_index]]
                            user_config['multi_column_mode'] = False
                            break
                        else:
                            print(f"‚ùå Vui l√≤ng ch·ªçn t·ª´ 1 ƒë·∫øn {len(df.columns)}")
                    else:
                        if choice in df.columns:
                            user_config['message_column'] = choice
                            user_config['selected_columns'] = [choice]
                            user_config['multi_column_mode'] = False
                            break
                        print("‚ùå T√™n c·ªôt kh√¥ng t·ªìn t·∫°i!")
                
                print(f"‚úÖ ƒê√£ ch·ªçn c·ªôt: '{user_config['message_column']}'")
                break
                
            elif mode_choice == "2":
                # Ch·∫ø ƒë·ªô ch·ªçn nhi·ªÅu c·ªôt
                print("\nüìù Nh·∫≠p c√°c s·ªë c·ªôt c·∫ßn x·ª≠ l√Ω, c√°ch nhau b·∫±ng d·∫•u ph·∫©y")
                print("   V√≠ d·ª•: 1,3,5 ho·∫∑c 2,4,6,8")
                
                while True:
                    choices = input(f"\nNh·∫≠p c√°c s·ªë c·ªôt (1-{len(df.columns)}): ").strip()
                    
                    try:
                        # Parse input
                        column_indices = [int(x.strip()) - 1 for x in choices.split(',')]
                        
                        # Validate indices
                        invalid_indices = [i+1 for i in column_indices if i < 0 or i >= len(df.columns)]
                        if invalid_indices:
                            print(f"‚ùå S·ªë c·ªôt kh√¥ng h·ª£p l·ªá: {invalid_indices}. Vui l√≤ng ch·ªçn t·ª´ 1 ƒë·∫øn {len(df.columns)}")
                            continue
                        
                        # Get column names
                        selected_columns = [df.columns[i] for i in column_indices]
                        
                        # Set config
                        user_config['selected_columns'] = selected_columns
                        user_config['message_column'] = selected_columns[0]  # First column as primary
                        user_config['multi_column_mode'] = True
                        
                        print(f"\n‚úÖ ƒê√£ ch·ªçn {len(selected_columns)} c·ªôt:")
                        for i, col in enumerate(selected_columns, 1):
                            print(f"  {i}. {col}")
                        break
                        
                    except ValueError:
                        print("‚ùå Format kh√¥ng ƒë√∫ng. Vui l√≤ng nh·∫≠p c√°c s·ªë c√°ch nhau b·∫±ng d·∫•u ph·∫©y (VD: 1,3,5)")
                break
            else:
                print("‚ùå Vui l√≤ng ch·ªçn 1 ho·∫∑c 2")
    else:
        print("‚ùå Kh√¥ng th·ªÉ load file ƒë·ªÉ ph√¢n t√≠ch c·ªôt")
        return None
    
    # 6. C·∫•u h√¨nh checkpoint
    print("\nüíæ B∆Ø·ªöC 6: C·∫•u h√¨nh checkpoint")
    print("-" * 40)
    
    while True:
        checkpoint_choice = input("S·ª≠ d·ª•ng checkpoint ƒë·ªÉ c√≥ th·ªÉ ti·∫øp t·ª•c khi b·ªã d·ª´ng? (y/n) [y]: ").strip().lower()
        if checkpoint_choice in ['', 'y', 'yes', 'c√≥']:
            user_config['use_checkpoint'] = True
            print("‚úÖ S·∫Ω s·ª≠ d·ª•ng checkpoint")
            break
        elif checkpoint_choice in ['n', 'no', 'kh√¥ng']:
            user_config['use_checkpoint'] = False
            print("‚úÖ Kh√¥ng s·ª≠ d·ª•ng checkpoint")
            break
        else:
            print("‚ùå Vui l√≤ng nh·∫≠p 'y' ho·∫∑c 'n'")
    
    # 7. Ch·ªçn output format  
    print("\nüìÑ B∆Ø·ªöC 7: Ch·ªçn ƒë·ªãnh d·∫°ng output")
    print("-" * 40)
    
    while True:
        print("Ch·ªçn ƒë·ªãnh d·∫°ng output:")
        print("  1. Text format (truy·ªÅn th·ªëng) - Compatible v·ªõi t·∫•t c·∫£ prompts")
        print("  2. JSON format (structured) - Ch√≠nh x√°c h∆°n, d·ªÖ parse")
        
        format_choice = input("\nCh·ªçn format (1 ho·∫∑c 2) [1]: ").strip()
        
        if format_choice in ['', '1']:
            user_config['use_json_output'] = False
            print("‚úÖ S·∫Ω s·ª≠ d·ª•ng text format")
            break
        elif format_choice == '2':
            user_config['use_json_output'] = True
            print("‚úÖ S·∫Ω s·ª≠ d·ª•ng JSON format") 
            print("üí° JSON format y√™u c·∫ßu prompt ph√π h·ª£p ho·∫∑c s·ª≠ d·ª•ng template json_classify")
            break
        else:
            print("‚ùå Vui l√≤ng ch·ªçn 1 ho·∫∑c 2")

    # 8. Nh·∫≠p prompt
    print("\n‚úçÔ∏è B∆Ø·ªöC 8: C·∫•u h√¨nh prompt AI")
    print("-" * 40)
    
    # Hi·ªÉn th·ªã c√°c template c√≥ s·∫µn, highlight JSON template n·∫øu ch·ªçn JSON
    print("C√°c template prompt c√≥ s·∫µn:")
    template_keys = list(DEFAULT_PROMPT_TEMPLATES.keys())
    for i, key in enumerate(template_keys, 1):
        if key == 'json_classify' and user_config['use_json_output']:
            print(f"  {i}. {key}: {DEFAULT_PROMPT_TEMPLATES[key][:50]}... üåü RECOMMENDED cho JSON")
        else:
            print(f"  {i}. {key}: {DEFAULT_PROMPT_TEMPLATES[key][:50]}...")
    
    print(f"  {len(template_keys) + 1}. ƒê·ªçc prompt t·ª´ file (.txt)")
    print(f"  {len(template_keys) + 2}. T·ª± nh·∫≠p prompt")
    
    while True:
        try:
            choice = input(f"\nCh·ªçn template (1-{len(template_keys) + 2}): ").strip()
            
            if choice.isdigit():
                template_index = int(choice) - 1
                if 0 <= template_index < len(template_keys):
                    # S·ª≠ d·ª•ng template c√≥ s·∫µn
                    template_key = template_keys[template_index]
                    user_config['prompt'] = DEFAULT_PROMPT_TEMPLATES[template_key]
                    print(f"‚úÖ ƒê√£ ch·ªçn template: {template_key}")
                    print(f"Prompt: {user_config['prompt']}")
                    break
                elif template_index == len(template_keys):
                    # ƒê·ªçc prompt t·ª´ file
                    prompt_from_file = load_prompt_from_file()
                    if prompt_from_file:
                        user_config['prompt'] = prompt_from_file
                        print(f"‚úÖ ƒê√£ load prompt t·ª´ file")
                        print(f"Prompt preview: {prompt_from_file[:200]}...")
                        break
                    else:
                        print("‚ùå Kh√¥ng th·ªÉ load prompt t·ª´ file, vui l√≤ng ch·ªçn l·∫°i")
                elif template_index == len(template_keys) + 1:
                    # T·ª± nh·∫≠p prompt
                    while True:
                        custom_prompt = input("\nNh·∫≠p prompt t√πy ch·ªânh: ").strip()
                        is_valid, message = validate_prompt(custom_prompt)
                        if is_valid:
                            user_config['prompt'] = custom_prompt
                            print(f"‚úÖ {message}")
                            break
                        else:
                            print(f"‚ùå {message}")
                    break
                else:
                    print(f"‚ùå Vui l√≤ng ch·ªçn t·ª´ 1 ƒë·∫øn {len(template_keys) + 2}")
            else:
                print("‚ùå Vui l√≤ng nh·∫≠p s·ªë h·ª£p l·ªá!")
        except ValueError:
            print("‚ùå Vui l√≤ng nh·∫≠p s·ªë h·ª£p l·ªá!")
    
    # 9. T·ªïng k·∫øt
    print("\nüìã B∆Ø·ªöC 9: T·ªïng k·∫øt c·∫•u h√¨nh")
    print("="*60)
    api_name = "Gemini" if user_config['api_provider'] == 'gemini' else "OpenAI"
    print(f"üîß API Provider: {api_name}")
    print(f"ü§ñ Model: {user_config['model_name']}")
    print(f"üìÅ File input: {Path(user_config['input_file']).name}")
    
    if user_config.get('multi_column_mode', False):
        print(f"üìä Ch·∫ø ƒë·ªô: Nhi·ªÅu c·ªôt ({len(user_config['selected_columns'])} c·ªôt)")
        for i, col in enumerate(user_config['selected_columns'], 1):
            print(f"     {i}. {col}")
    else:
        print(f"üìä C·ªôt x·ª≠ l√Ω: {user_config['message_column']}")
    
    print(f"üíæ Checkpoint: {'C√≥' if user_config['use_checkpoint'] else 'Kh√¥ng'}")
    output_format = "JSON" if user_config.get('use_json_output', False) else "Text"
    print(f"üìÑ Output format: {output_format}")
    print(f"‚úçÔ∏è Prompt: {user_config['prompt'][:100]}...")
    
    while True:
        confirm = input("\nX√°c nh·∫≠n b·∫Øt ƒë·∫ßu x·ª≠ l√Ω? (y/n): ").strip().lower()
        if confirm in ['y', 'yes', 'c√≥']:
            print("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
            return user_config
        elif confirm in ['n', 'no', 'kh√¥ng']:
            print("‚ùå ƒê√£ h·ªßy")
            return None
        else:
            print("‚ùå Vui l√≤ng nh·∫≠p 'y' ho·∫∑c 'n'")

def display_help():
    """Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"""
    print("""
üöÄ AI ETL DATA - H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
================================

üìã M√î T·∫¢:
C√¥ng c·ª• x·ª≠ l√Ω d·ªØ li·ªáu text b·∫±ng AI (Gemini v√† OpenAI), h·ªó tr·ª£ ƒëa d·∫°ng c√°c t√°c v·ª•:
- T√≥m t·∫Øt vƒÉn b·∫£n
- Ph√¢n lo·∫°i n·ªôi dung  
- Ph√¢n t√≠ch c·∫£m x√∫c
- Tr√≠ch xu·∫•t t·ª´ kh√≥a
- D·ªãch thu·∫≠t
- V√† nhi·ªÅu t√°c v·ª• kh√°c t√πy ch·ªânh

ü§ñ API H·ªñ TR·ª¢:
- Gemini AI (Google): gemma-3-27b-it, gemini-2.0-flash, gemini-2.5-flash
- OpenAI: gpt-3.5-turbo, gpt-4, gpt-4-turbo, gpt-4o, gpt-4o-mini

üìÅ ƒê·ªäNH D·∫†NG FILE H·ªñ TR·ª¢:
- Excel (.xlsx, .xls)
- CSV (.csv)

‚öôÔ∏è T√çNH NƒÇNG:
‚úÖ H·ªó tr·ª£ c·∫£ Gemini AI v√† OpenAI API
‚úÖ T·ª± ƒë·ªông ph√°t hi·ªán c·ªôt d·ªØ li·ªáu
‚úÖ Checkpoint ƒë·ªÉ ti·∫øp t·ª•c khi b·ªã d·ª´ng
‚úÖ Prompt templates c√≥ s·∫µn + ƒë·ªçc t·ª´ file .txt
‚úÖ B√°o c√°o ti·∫øn tr√¨nh real-time
‚úÖ X·ª≠ l√Ω l·ªói th√¥ng minh
‚úÖ Xu·∫•t k·∫øt qu·∫£ c√πng th∆∞ m·ª•c

üöÄ C√ÅCH S·ª¨ D·ª§NG:
1. Ch·∫°y: python main.py
2. Ch·ªçn API Provider (Gemini/OpenAI)
3. Nh·∫≠p API Key
4. Ch·ªçn model AI
5. Ch·ªçn file d·ªØ li·ªáu (.xlsx/.csv)
6. Ch·ªçn c·ªôt c·∫ßn x·ª≠ l√Ω
7. C·∫•u h√¨nh checkpoint
8. Ch·ªçn/nh·∫≠p prompt (template c√≥ s·∫µn, file .txt, ho·∫∑c t·ª± nh·∫≠p)
9. X√°c nh·∫≠n v√† b·∫Øt ƒë·∫ßu

üìä K·∫æT QU·∫¢:
- File k·∫øt qu·∫£: <t√™n_file>_ai_result_<timestamp>.<ƒë·ªãnh_d·∫°ng>
- File checkpoint: <t√™n_file>_checkpoint.<ƒë·ªãnh_d·∫°ng>
- Log file: ai_etl_data.log

üí° M·∫∏O:
- S·ª≠ d·ª•ng checkpoint ƒë·ªÉ x·ª≠ l√Ω file l·ªõn
- Prompt c√†ng c·ª• th·ªÉ k·∫øt qu·∫£ c√†ng t·ªët
- Ki·ªÉm tra API Key c√≥ quy·ªÅn truy c·∫≠p model
""")

def show_main_menu():
    """Hi·ªÉn th·ªã menu ch√≠nh"""
    print("\nüöÄ AI ETL DATA - C√îNG C·ª§ X·ª¨ L√ù D·ªÆ LI·ªÜU V·ªöI AI")
    print("="*60)
    print("ü§ñ H·ªñ TR·ª¢ MULTI-API:")
    print("   üî• Gemini AI: gemma-3-27b-it, gemini-2.0-flash, gemini-2.5-flash")
    print("   üß† OpenAI: gpt-3.5-turbo, gpt-4, gpt-4-turbo, gpt-4o, gpt-4o-mini")
    print("üìã T√çNH NƒÇNG CH√çNH:")
    print("   ‚úÖ X·ª≠ l√Ω file Excel/CSV v·ªõi checkpoint th√¥ng minh")
    print("   ‚úÖ Template prompt ƒëa d·∫°ng + ƒë·ªçc prompt t·ª´ file")
    print("   ‚úÖ X·ª≠ l√Ω ƒëa c·ªôt (multi-column) v·ªõi AI analysis")
    print("   ‚úÖ Batch Processing: TƒÉng t·ªëc 5-10x")
    print("   ‚úÖ Parallel Processing: TƒÉng t·ªëc 15-30x")
    print("   ‚úÖ Monitoring real-time v·ªõi progress bar")
    print("   ‚úÖ Error handling v√† auto-recovery")
    print("="*60)
    print("üéØ B·∫Øt ƒë·∫ßu th√¥i!")
    print()

if __name__ == "__main__":
    display_help() 