import pandas as pd
import numpy as np
import os
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path
import google.generativeai as genai
from tqdm import tqdm
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue
import traceback

# Import config
from config import (
    MAX_OUTPUT_TOKENS,
    TEMPERATURE, 
    TOP_P,
    TOP_K,
    MAX_RETRIES,
    RETRY_DELAY,
    REQUEST_DELAY,
    SUPPORTED_FORMATS,
    LOG_FILE,
    LOG_LEVEL,
    BATCH_SIZE,
    ENABLE_BATCH_PROCESSING,
    ENABLE_PARALLEL_PROCESSING,
    MAX_CONCURRENT_THREADS,
    THREAD_BATCH_SIZE,
    RATE_LIMIT_DELAY,
    MAX_RETRIES_PER_THREAD,
    THREAD_TIMEOUT,
    CIRCUIT_BREAKER_THRESHOLD
)

def setup_logging():
    """Thi·∫øt l·∫≠p logging cho ·ª©ng d·ª•ng"""
    logging.basicConfig(
        level=getattr(logging, LOG_LEVEL),
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(LOG_FILE, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

def initialize_gemini(api_key, model_name):
    """Kh·ªüi t·∫°o Gemini API v·ªõi c·∫•u h√¨nh"""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(
            model_name=model_name,
            generation_config={
                "max_output_tokens": MAX_OUTPUT_TOKENS,
                "temperature": TEMPERATURE,
                "top_p": TOP_P,
                "top_k": TOP_K,
            }
        )
        logger.info(f"‚úÖ ƒê√£ kh·ªüi t·∫°o Gemini model: {model_name}")
        return model
    except Exception as e:
        logger.error(f"‚ùå L·ªói kh·ªüi t·∫°o Gemini: {str(e)}")
        return None

def validate_file_path(file_path):
    """Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa ƒë∆∞·ªùng d·∫´n file"""
    if not file_path:
        return False, "ƒê∆∞·ªùng d·∫´n file kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
    
    path = Path(file_path)
    
    # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i
    if not path.exists():
        return False, f"File kh√¥ng t·ªìn t·∫°i: {file_path}"
    
    # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
    if path.suffix.lower() not in SUPPORTED_FORMATS:
        return False, f"ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Ch·ªâ h·ªó tr·ª£: {', '.join(SUPPORTED_FORMATS)}"
    
    return True, "File h·ª£p l·ªá"

def load_data(file_path):
    """Load d·ªØ li·ªáu t·ª´ file Excel ho·∫∑c CSV"""
    try:
        file_ext = Path(file_path).suffix.lower()
        
        if file_ext in ['.xlsx', '.xls']:
            df = pd.read_excel(file_path)
        elif file_ext == '.csv':
            # Th·ª≠ nhi·ªÅu encoding ƒë·ªÉ tr√°nh l·ªói
            encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252']
            df = None
            for encoding in encodings:
                try:
                    df = pd.read_csv(file_path, encoding=encoding)
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                raise Exception("Kh√¥ng th·ªÉ ƒë·ªçc file CSV v·ªõi c√°c encoding th√¥ng d·ª•ng")
        else:
            raise Exception(f"ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_ext}")
        
        logger.info(f"‚úÖ ƒê√£ load file: {file_path} ({len(df)} records)")
        return df
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói load file: {str(e)}")
        return None

def save_data(df, file_path):
    """L∆∞u d·ªØ li·ªáu ra file Excel ho·∫∑c CSV"""
    try:
        file_ext = Path(file_path).suffix.lower()
        
        if file_ext in ['.xlsx', '.xls']:
            df.to_excel(file_path, index=False)
        elif file_ext == '.csv':
            df.to_csv(file_path, index=False, encoding='utf-8-sig')
        else:
            raise Exception(f"ƒê·ªãnh d·∫°ng file output kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_ext}")
        
        logger.info(f"‚úÖ ƒê√£ l∆∞u file: {file_path}")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói l∆∞u file: {str(e)}")
        return False

def detect_message_column(df):
    """T·ª± ƒë·ªông ph√°t hi·ªán c·ªôt ch·ª©a message"""
    possible_columns = ['MESSAGE']
    
    for col in possible_columns:
        if col in df.columns:
            return col
    
    # N·∫øu kh√¥ng t√¨m th·∫•y, tr·∫£ v·ªÅ c·ªôt ƒë·∫ßu ti√™n c√≥ ki·ªÉu text
    for col in df.columns:
        if df[col].dtype == 'object':
            return col
    
    return None

def generate_output_filename(input_file):
    """T·∫°o t√™n file output d·ª±a tr√™n file input"""
    input_path = Path(input_file)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_name = f"{input_path.stem}_ai_result_{timestamp}{input_path.suffix}"
    return str(input_path.parent / output_name)

def generate_checkpoint_filename(input_file):
    """T·∫°o t√™n file checkpoint d·ª±a tr√™n file input"""
    input_path = Path(input_file)
    checkpoint_name = f"{input_path.stem}_checkpoint{input_path.suffix}"
    return str(input_path.parent / checkpoint_name)

def load_checkpoint(checkpoint_file):
    """Load checkpoint n·∫øu t·ªìn t·∫°i"""
    try:
        if os.path.exists(checkpoint_file):
            df = load_data(checkpoint_file)
            if df is not None:
                logger.info(f"üîÑ ƒê√£ load checkpoint: {checkpoint_file}")
                return df
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è L·ªói load checkpoint: {str(e)}")
    
    return None

def save_checkpoint(df, checkpoint_file):
    """L∆∞u checkpoint"""
    try:
        save_data(df, checkpoint_file)
        logger.info(f"üíæ ƒê√£ l∆∞u checkpoint: {checkpoint_file}")
    except Exception as e:
        logger.error(f"‚ùå L·ªói l∆∞u checkpoint: {str(e)}")

def process_text_with_ai(model, text, prompt, max_retries=MAX_RETRIES):
    """X·ª≠ l√Ω text v·ªõi AI model"""
    for attempt in range(max_retries):
        try:
            # T·∫°o prompt ƒë·∫ßy ƒë·ªß
            full_prompt = f"{prompt}\n\nN·ªôi dung c·∫ßn x·ª≠ l√Ω:\n{text}\n\nK·∫øt qu·∫£:"
            
            # G·ªçi API
            response = model.generate_content(full_prompt)
            
            # Delay ƒë·ªÉ tr√°nh rate limit
            time.sleep(REQUEST_DELAY)
            
            if response and response.text:
                result = response.text.strip()
                logger.debug(f"‚úÖ X·ª≠ l√Ω th√†nh c√¥ng: {text[:50]}...")
                return result
            else:
                raise Exception("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c response t·ª´ AI")
                
        except Exception as e:
            error_msg = str(e)
            
            # X·ª≠ l√Ω l·ªói rate limit
            if "429" in error_msg or "quota" in error_msg.lower():
                if attempt < max_retries - 1:
                    wait_time = RETRY_DELAY * (attempt + 1)  # TƒÉng d·∫ßn th·ªùi gian ch·ªù
                    logger.warning(f"‚è≥ Rate limit reached. Ch·ªù {wait_time} gi√¢y...")
                    time.sleep(wait_time)
                    continue
            
            # X·ª≠ l√Ω l·ªói kh√°c
            logger.error(f"‚ùå L·ªói x·ª≠ l√Ω text (attempt {attempt + 1}): {error_msg}")
            
            if attempt < max_retries - 1:
                time.sleep(5)  # Ch·ªù ng·∫Øn tr∆∞·ªõc khi th·ª≠ l·∫°i
                continue
    
    return f"L·ªói x·ª≠ l√Ω sau {max_retries} l·∫ßn th·ª≠"

def process_multicolumn_with_ai(model, row_data, column_names, prompt, max_retries=MAX_RETRIES):
    """X·ª≠ l√Ω nhi·ªÅu c·ªôt v·ªõi AI model"""
    try:
        # T·∫°o c·∫•u tr√∫c d·ªØ li·ªáu cho prompt
        data_structure = "\n".join([
            f"{i+1}. {col_name}: {clean_text(str(row_data.get(col_name, 'N/A')))}"
            for i, col_name in enumerate(column_names)
        ])
        
        # T·∫°o ph·∫ßn ƒë·ªãnh nghƒ©a c·ªôt cho prompt
        column_definitions = "\n".join([
            f"- C·ªôt {i+1} ({col_name}): {_get_column_description(col_name)}"
            for i, col_name in enumerate(column_names)
        ])
        
        # T·∫°o prompt ƒë·∫ßy ƒë·ªß v·ªõi ƒë·ªãnh nghƒ©a c·ªôt
        full_prompt = f"""
{prompt}

TH√îNG TIN C√ÅC C·ªòT:
{column_definitions}

D·ªÆ LI·ªÜU C·∫¶N X·ª¨ L√ù:
{data_structure}

K·∫øt qu·∫£:"""
        
        # G·ªçi h√†m x·ª≠ l√Ω AI
        return process_text_with_ai(model, "", full_prompt, max_retries)
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói x·ª≠ l√Ω multi-column: {str(e)}")
        return f"L·ªói x·ª≠ l√Ω multi-column: {str(e)}"

def _get_column_description(column_name):
    """T·∫°o m√¥ t·∫£ cho c·ªôt d·ª±a tr√™n t√™n c·ªôt"""
    return column_name

def process_batch_with_ai(model, batch_data, prompt, max_retries=MAX_RETRIES):
    """X·ª≠ l√Ω batch data v·ªõi AI model - single column mode"""
    try:
        # T·∫°o prompt cho batch processing
        batch_items = []
        for i, item in enumerate(batch_data, 1):
            cleaned_text = clean_text(str(item))
            batch_items.append(f"[{i}] {cleaned_text}")
        
        batch_content = "\n\n".join(batch_items)
        
        # T·∫°o prompt ƒë·∫ßy ƒë·ªß cho batch
        full_prompt = f"""{prompt}

H∆Ø·ªöNG D·∫™N BATCH PROCESSING:
- X·ª≠ l√Ω {len(batch_data)} m·ª•c d·ªØ li·ªáu d∆∞·ªõi ƒë√¢y
- Tr·∫£ v·ªÅ k·∫øt qu·∫£ theo th·ª© t·ª± t∆∞∆°ng ·ª©ng
- Format: [1] K·∫øt qu·∫£ 1\n[2] K·∫øt qu·∫£ 2\n[3] K·∫øt qu·∫£ 3...

D·ªÆ LI·ªÜU C·∫¶N X·ª¨ L√ù:
{batch_content}

K·∫æT QU·∫¢:"""

        # G·ªçi AI
        for attempt in range(max_retries):
            try:
                response = model.generate_content(full_prompt)
                
                # Delay ƒë·ªÉ tr√°nh rate limit  
                time.sleep(REQUEST_DELAY)
                
                if response and response.text:
                    # Parse k·∫øt qu·∫£ batch
                    results = parse_batch_results(response.text.strip(), len(batch_data))
                    logger.debug(f"‚úÖ X·ª≠ l√Ω batch th√†nh c√¥ng: {len(results)} results")
                    return results
                else:
                    raise Exception("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c response t·ª´ AI")
                    
            except Exception as e:
                error_msg = str(e)
                
                # X·ª≠ l√Ω l·ªói rate limit
                if "429" in error_msg or "quota" in error_msg.lower():
                    if attempt < max_retries - 1:
                        wait_time = RETRY_DELAY * (attempt + 1)
                        logger.warning(f"‚è≥ Rate limit reached. Ch·ªù {wait_time} gi√¢y...")
                        time.sleep(wait_time)
                        continue
                
                # X·ª≠ l√Ω l·ªói kh√°c
                logger.error(f"‚ùå L·ªói x·ª≠ l√Ω batch (attempt {attempt + 1}): {error_msg}")
                
                if attempt < max_retries - 1:
                    time.sleep(5)
                    continue
        
        # N·∫øu batch th·∫•t b·∫°i, fallback v·ªÅ single processing
        logger.warning("‚ö†Ô∏è Batch processing th·∫•t b·∫°i, fallback v·ªÅ single processing")
        results = []
        for item in batch_data:
            result = process_text_with_ai(model, str(item), prompt, max_retries)
            results.append(result)
        return results
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói x·ª≠ l√Ω batch: {str(e)}")
        # Fallback v·ªÅ single processing
        results = []
        for item in batch_data:
            result = process_text_with_ai(model, str(item), prompt, max_retries)
            results.append(result)
        return results

def process_multicolumn_batch_with_ai(model, batch_rows, column_names, prompt, max_retries=MAX_RETRIES):
    """X·ª≠ l√Ω batch data v·ªõi AI model - multi-column mode"""
    try:
        # T·∫°o prompt cho multi-column batch processing
        batch_items = []
        
        # T·∫°o ph·∫ßn ƒë·ªãnh nghƒ©a c·ªôt
        column_definitions = "\n".join([
            f"- C·ªôt {i+1} ({col_name}): {_get_column_description(col_name)}"
            for i, col_name in enumerate(column_names)
        ])
        
        # T·∫°o d·ªØ li·ªáu batch
        for i, row_data in enumerate(batch_rows, 1):
            data_structure = "\n".join([
                f"  {j+1}. {col_name}: {clean_text(str(row_data.get(col_name, 'N/A')))}"
                for j, col_name in enumerate(column_names)
            ])
            batch_items.append(f"[{i}]\n{data_structure}")
        
        batch_content = "\n\n".join(batch_items)
        
        # T·∫°o prompt ƒë·∫ßy ƒë·ªß cho multi-column batch
        full_prompt = f"""{prompt}

TH√îNG TIN C√ÅC C·ªòT:
{column_definitions}

H∆Ø·ªöNG D·∫™N BATCH PROCESSING:
- X·ª≠ l√Ω {len(batch_rows)} m·ª•c d·ªØ li·ªáu d∆∞·ªõi ƒë√¢y
- M·ªói m·ª•c c√≥ {len(column_names)} c·ªôt th√¥ng tin
- Tr·∫£ v·ªÅ k·∫øt qu·∫£ theo th·ª© t·ª± t∆∞∆°ng ·ª©ng
- Format: [1] K·∫øt qu·∫£ 1\n[2] K·∫øt qu·∫£ 2\n[3] K·∫øt qu·∫£ 3...

D·ªÆ LI·ªÜU C·∫¶N X·ª¨ L√ù:
{batch_content}

K·∫æT QU·∫¢:"""

        # G·ªçi AI
        for attempt in range(max_retries):
            try:
                response = model.generate_content(full_prompt)
                
                # Delay ƒë·ªÉ tr√°nh rate limit
                time.sleep(REQUEST_DELAY)
                
                if response and response.text:
                    # Parse k·∫øt qu·∫£ batch
                    results = parse_batch_results(response.text.strip(), len(batch_rows))
                    logger.debug(f"‚úÖ X·ª≠ l√Ω multi-column batch th√†nh c√¥ng: {len(results)} results")
                    return results
                else:
                    raise Exception("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c response t·ª´ AI")
                    
            except Exception as e:
                error_msg = str(e)
                
                # X·ª≠ l√Ω l·ªói rate limit
                if "429" in error_msg or "quota" in error_msg.lower():
                    if attempt < max_retries - 1:
                        wait_time = RETRY_DELAY * (attempt + 1)
                        logger.warning(f"‚è≥ Rate limit reached. Ch·ªù {wait_time} gi√¢y...")
                        time.sleep(wait_time)
                        continue
                
                # X·ª≠ l√Ω l·ªói kh√°c
                logger.error(f"‚ùå L·ªói x·ª≠ l√Ω multi-column batch (attempt {attempt + 1}): {error_msg}")
                
                if attempt < max_retries - 1:
                    time.sleep(5)
                    continue
        
        # N·∫øu batch th·∫•t b·∫°i, fallback v·ªÅ single processing
        logger.warning("‚ö†Ô∏è Multi-column batch processing th·∫•t b·∫°i, fallback v·ªÅ single processing")
        results = []
        for row_data in batch_rows:
            result = process_multicolumn_with_ai(model, row_data, column_names, prompt, max_retries)
            results.append(result)
        return results
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói x·ª≠ l√Ω multi-column batch: {str(e)}")
        # Fallback v·ªÅ single processing
        results = []
        for row_data in batch_rows:
            result = process_multicolumn_with_ai(model, row_data, column_names, prompt, max_retries)
            results.append(result)
        return results

def parse_batch_results(response_text, expected_count):
    """Parse k·∫øt qu·∫£ t·ª´ batch response"""
    try:
        results = []
        lines = response_text.split('\n')
        
        current_result = ""
        current_index = 0
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Ki·ªÉm tra n·∫øu l√† d√≤ng b·∫Øt ƒë·∫ßu v·ªõi [s·ªë]
            if line.startswith('[') and ']' in line:
                # L∆∞u k·∫øt qu·∫£ tr∆∞·ªõc ƒë√≥ n·∫øu c√≥
                if current_result and current_index > 0:
                    results.append(current_result.strip())
                
                # B·∫Øt ƒë·∫ßu k·∫øt qu·∫£ m·ªõi
                bracket_end = line.find(']')
                try:
                    index = int(line[1:bracket_end])
                    current_index = index
                    current_result = line[bracket_end + 1:].strip()
                except ValueError:
                    # N·∫øu kh√¥ng parse ƒë∆∞·ª£c s·ªë, coi nh∆∞ l√† n·ªôi dung
                    current_result += " " + line
            else:
                # Ti·∫øp t·ª•c n·ªôi dung c·ªßa k·∫øt qu·∫£ hi·ªán t·∫°i
                current_result += " " + line
        
        # L∆∞u k·∫øt qu·∫£ cu·ªëi c√πng
        if current_result and current_index > 0:
            results.append(current_result.strip())
        
        # ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng k·∫øt qu·∫£ ƒë√∫ng
        while len(results) < expected_count:
            results.append("L·ªói parse k·∫øt qu·∫£")
        
        # C·∫Øt b·ªõt n·∫øu c√≥ qu√° nhi·ªÅu k·∫øt qu·∫£
        results = results[:expected_count]
        
        logger.debug(f"‚úÖ Parse batch results: {len(results)}/{expected_count}")
        return results
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói parse batch results: {str(e)}")
        # Fallback: tr·∫£ v·ªÅ response nguy√™n cho t·∫•t c·∫£
        return [response_text] * expected_count

# ===========================
# PARALLEL PROCESSING FUNCTIONS
# ===========================

class CircuitBreaker:
    """Circuit breaker pattern cho parallel processing"""
    def __init__(self, threshold=CIRCUIT_BREAKER_THRESHOLD):
        self.threshold = threshold
        self.failure_count = 0
        self.last_failure_time = None
        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN
        self.reset_timeout = 60  # seconds
        self._lock = threading.Lock()
    
    def call(self, func, *args, **kwargs):
        """G·ªçi function v·ªõi circuit breaker protection"""
        with self._lock:
            if self.state == 'OPEN':
                if time.time() - self.last_failure_time > self.reset_timeout:
                    self.state = 'HALF_OPEN'
                else:
                    raise Exception("Circuit breaker is OPEN")
            
            try:
                result = func(*args, **kwargs)
                if self.state == 'HALF_OPEN':
                    self.state = 'CLOSED'
                    self.failure_count = 0
                return result
            
            except Exception as e:
                self.failure_count += 1
                self.last_failure_time = time.time()
                
                if self.failure_count >= self.threshold:
                    self.state = 'OPEN'
                    logger.warning(f"üî¥ Circuit breaker OPEN - {self.failure_count} failures")
                
                raise e

def process_parallel_batch_worker(thread_id, model, batch_data, column_names, prompt, is_multicolumn, circuit_breaker, progress_queue):
    """Worker function cho parallel processing"""
    try:
        logger.info(f"üöÄ Thread {thread_id} b·∫Øt ƒë·∫ßu x·ª≠ l√Ω {len(batch_data)} items")
        
        # Delay staggered ƒë·ªÉ tr√°nh rate limit
        time.sleep(thread_id * RATE_LIMIT_DELAY)
        
        # X·ª≠ l√Ω v·ªõi circuit breaker protection
        if is_multicolumn:
            results = circuit_breaker.call(
                process_multicolumn_batch_with_ai,
                model, batch_data, column_names, prompt, MAX_RETRIES_PER_THREAD
            )
        else:
            results = circuit_breaker.call(
                process_batch_with_ai,
                model, batch_data, prompt, MAX_RETRIES_PER_THREAD
            )
        
        # Report progress
        progress_queue.put(('success', thread_id, len(batch_data)))
        logger.info(f"‚úÖ Thread {thread_id} ho√†n th√†nh th√†nh c√¥ng")
        
        return results
        
    except Exception as e:
        error_msg = f"Thread {thread_id} l·ªói: {str(e)}"
        logger.error(f"‚ùå {error_msg}")
        logger.debug(traceback.format_exc())
        
        # Report error
        progress_queue.put(('error', thread_id, str(e)))
        
        # Fallback v·ªÅ single processing cho batch n√†y
        results = []
        try:
            if is_multicolumn:
                for row_data in batch_data:
                    result = process_multicolumn_with_ai(model, row_data, column_names, prompt, MAX_RETRIES_PER_THREAD)
                    results.append(result)
            else:
                for item in batch_data:
                    result = process_text_with_ai(model, str(item), prompt, MAX_RETRIES_PER_THREAD)
                    results.append(result)
        except Exception as fallback_error:
            logger.error(f"‚ùå Thread {thread_id} fallback c≈©ng th·∫•t b·∫°i: {str(fallback_error)}")
            results = [f"L·ªói x·ª≠ l√Ω: {str(e)}"] * len(batch_data)
        
        return results

def process_data_parallel(model, data, column_names, prompt, is_multicolumn=False):
    """X·ª≠ l√Ω d·ªØ li·ªáu v·ªõi parallel processing"""
    if not ENABLE_PARALLEL_PROCESSING:
        logger.info("üîÑ Parallel processing b·ªã t·∫Øt, chuy·ªÉn v·ªÅ batch processing")
        return process_data_batch_only(model, data, column_names, prompt, is_multicolumn)
    
    try:
        total_items = len(data)
        logger.info(f"üöÄ B·∫Øt ƒë·∫ßu parallel processing: {total_items} items v·ªõi {MAX_CONCURRENT_THREADS} threads")
        
        # Chia d·ªØ li·ªáu th√†nh c√°c batches cho c√°c threads
        thread_batches = []
        batch_size = THREAD_BATCH_SIZE
        
        for i in range(0, total_items, batch_size):
            batch = data[i:i+batch_size]
            thread_batches.append(batch)
        
        logger.info(f"üì¶ ƒê√£ chia th√†nh {len(thread_batches)} batches, m·ªói batch {batch_size} items")
        
        # Setup circuit breaker v√† progress tracking
        circuit_breaker = CircuitBreaker()
        progress_queue = Queue()
        all_results = [None] * len(thread_batches)
        
        # Progress tracking
        completed_threads = 0
        total_processed = 0
        start_time = time.time()
        
        # Ch·∫°y parallel processing v·ªõi ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT_THREADS) as executor:
            # Submit all tasks
            future_to_index = {}
            for i, batch in enumerate(thread_batches):
                future = executor.submit(
                    process_parallel_batch_worker,
                    i, model, batch, column_names, prompt, is_multicolumn, circuit_breaker, progress_queue
                )
                future_to_index[future] = i
            
            # Collect results v·ªõi progress tracking
            with tqdm(total=total_items, desc="üîÑ Parallel Processing") as pbar:
                for future in as_completed(future_to_index, timeout=THREAD_TIMEOUT):
                    try:
                        index = future_to_index[future]
                        results = future.result()
                        all_results[index] = results
                        
                        # Update progress
                        batch_size_actual = len(thread_batches[index])
                        total_processed += batch_size_actual
                        completed_threads += 1
                        pbar.update(batch_size_actual)
                        
                        # Progress report
                        elapsed = time.time() - start_time
                        rate = total_processed / elapsed if elapsed > 0 else 0
                        logger.info(f"üìà Thread {index} ho√†n th√†nh - T·ªïng: {total_processed}/{total_items} ({rate:.2f} items/s)")
                        
                    except Exception as e:
                        index = future_to_index[future]
                        logger.error(f"‚ùå Thread {index} timeout ho·∫∑c l·ªói: {str(e)}")
                        # T·∫°o k·∫øt qu·∫£ l·ªói cho batch n√†y
                        batch_size_error = len(thread_batches[index])
                        all_results[index] = [f"L·ªói timeout: {str(e)}"] * batch_size_error
        
        # Flatten results
        final_results = []
        for batch_results in all_results:
            if batch_results:
                final_results.extend(batch_results)
        
        # Validation
        if len(final_results) != total_items:
            logger.warning(f"‚ö†Ô∏è S·ªë l∆∞·ª£ng k·∫øt qu·∫£ kh√¥ng kh·ªõp: {len(final_results)} vs {total_items}")
            # Pad with error messages if needed
            while len(final_results) < total_items:
                final_results.append("L·ªói: thi·∫øu k·∫øt qu·∫£")
        
        # Final summary
        elapsed = time.time() - start_time
        rate = total_processed / elapsed if elapsed > 0 else 0
        logger.info(f"üéâ Parallel processing ho√†n th√†nh: {total_processed}/{total_items} trong {elapsed:.1f}s ({rate:.2f} items/s)")
        
        return final_results
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói parallel processing: {str(e)}")
        logger.info("üîÑ Fallback v·ªÅ batch processing")
        return process_data_batch_only(model, data, column_names, prompt, is_multicolumn)

def process_data_batch_only(model, data, column_names, prompt, is_multicolumn=False):
    """X·ª≠ l√Ω d·ªØ li·ªáu ch·ªâ v·ªõi batch processing (kh√¥ng parallel)"""
    try:
        total_items = len(data)
        batch_size = BATCH_SIZE
        all_results = []
        
        logger.info(f"üì¶ Batch processing: {total_items} items v·ªõi batch size {batch_size}")
        
        with tqdm(total=total_items, desc="üîÑ Batch Processing") as pbar:
            for i in range(0, total_items, batch_size):
                batch = data[i:i+batch_size]
                
                if is_multicolumn:
                    results = process_multicolumn_batch_with_ai(model, batch, column_names, prompt)
                else:
                    results = process_batch_with_ai(model, batch, prompt)
                
                all_results.extend(results)
                pbar.update(len(batch))
        
        return all_results
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói batch processing: {str(e)}")
        # Fallback v·ªÅ single processing
        results = []
        for item in data:
            if is_multicolumn:
                result = process_multicolumn_with_ai(model, item, column_names, prompt)
            else:
                result = process_text_with_ai(model, str(item), prompt)
            results.append(result)
        return results

def estimate_completion_time(processed, total, start_time):
    """∆Ø·ªõc t√≠nh th·ªùi gian ho√†n th√†nh"""
    if processed == 0:
        return "Kh√¥ng th·ªÉ ∆∞·ªõc t√≠nh"
    
    elapsed = time.time() - start_time
    rate = processed / elapsed  # records per second
    remaining = total - processed
    
    if rate > 0:
        eta_seconds = remaining / rate
        eta = datetime.now() + timedelta(seconds=eta_seconds)
        return f"D·ª± ki·∫øn ho√†n th√†nh: {eta.strftime('%H:%M:%S %d/%m/%Y')}"
    
    return "Kh√¥ng th·ªÉ ∆∞·ªõc t√≠nh"

def print_progress_summary(processed, total, start_time, errors=0):
    """In b√°o c√°o ti·∫øn tr√¨nh chi ti·∫øt"""
    elapsed = time.time() - start_time
    rate = processed / elapsed if elapsed > 0 else 0
    
    print(f"\n{'='*60}")
    print(f"üìä B√ÅO C√ÅO TI·∫æN TR√åNH:")
    print(f"‚úÖ ƒê√£ x·ª≠ l√Ω: {processed}/{total} ({processed/total*100:.1f}%)")
    print(f"‚ö° T·ªëc ƒë·ªô: {rate:.2f} records/gi√¢y")
    print(f"‚è±Ô∏è Th·ªùi gian ƒë√£ ch·∫°y: {elapsed/3600:.1f} gi·ªù")
    print(f"‚ùå L·ªói: {errors}")
    print(f"‚è∞ {estimate_completion_time(processed, total, start_time)}")
    print(f"{'='*60}\n")

def validate_prompt(prompt):
    """Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa prompt"""
    if not prompt or prompt.strip() == "":
        return False, "Prompt kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
    
    if len(prompt.strip()) < 10:
        return False, "Prompt qu√° ng·∫Øn (t·ªëi thi·ªÉu 10 k√Ω t·ª±)"
    
    return True, "Prompt h·ª£p l·ªá"

def clean_text(text):
    """L√†m s·∫°ch text tr∆∞·ªõc khi x·ª≠ l√Ω"""
    if pd.isna(text):
        return ""
    
    text = str(text).strip()
    
    # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën
    text = text.replace('\n\n\n', '\n\n')
    text = text.replace('\t', ' ')
    
    return text

def get_processing_stats(df, result_column):
    """L·∫•y th·ªëng k√™ qu√° tr√¨nh x·ª≠ l√Ω"""
    if result_column not in df.columns:
        return {
            'total': len(df),
            'processed': 0,
            'remaining': len(df),
            'errors': 0
        }
    
    total = len(df)
    processed = len(df[df[result_column].notna() & (df[result_column] != "")])
    errors = len(df[df[result_column].str.contains("L·ªói", na=False)])
    remaining = total - processed
    
    return {
        'total': total,
        'processed': processed,
        'remaining': remaining,
        'errors': errors
    } 